{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7894853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import tree\n",
    "\n",
    "fullFilename = 'C:/Users/Zander/Desktop/Decision_Tree/Garmin_Health_Data.csv'\n",
    "health_data = pd.read_csv(fullFilename,sep =';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "22b91c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatset:: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average_Resting</th>\n",
       "      <th>Average_HRV</th>\n",
       "      <th>Avergage_Resting_Week1</th>\n",
       "      <th>Avergage_HRV_Week1</th>\n",
       "      <th>Avergage_Resting_Week2</th>\n",
       "      <th>Avergage_HRV_Week2</th>\n",
       "      <th>Classfication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>92</td>\n",
       "      <td>62</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>82</td>\n",
       "      <td>72</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>72</td>\n",
       "      <td>52</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>69</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>69</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average_Resting  Average_HRV  Avergage_Resting_Week1  Avergage_HRV_Week1  \\\n",
       "0               55           90                      60                  92   \n",
       "1               61           82                      72                  75   \n",
       "2               54           70                      50                  72   \n",
       "3               59           87                      70                  85   \n",
       "4               71           91                      75                  75   \n",
       "\n",
       "   Avergage_Resting_Week2  Avergage_HRV_Week2  Classfication  \n",
       "0                      62                  89              0  \n",
       "1                      75                  72              1  \n",
       "2                      52                  69              0  \n",
       "3                      69                  83              0  \n",
       "4                      69                  79              0  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Datatset:: \")\n",
    "health_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9d589519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = health_data.values[:, 0:5]\n",
    "Y = health_data.values[:, 6]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "Depression_Entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=5)\n",
    "Depression_Entropy.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "637355da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 5,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Depression_Entropy.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "23553cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction\n",
    "Y_pred_en = Depression_Entropy.predict(X_test)\n",
    "Y_pred_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "515713e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 55, 103,  72,  97,  73],\n",
       "       [ 56, 111,  56, 115,  61],\n",
       "       [ 64,  83,  84,  77,  74],\n",
       "       [ 65,  74,  70,  77,  76],\n",
       "       [ 53, 101,  71,  94,  67],\n",
       "       [ 80, 106,  84, 107,  92],\n",
       "       [ 71, 102,  89,  93,  84],\n",
       "       [ 70,  76,  78,  77,  87],\n",
       "       [ 54, 115,  64, 107,  74],\n",
       "       [ 64, 109,  65, 113,  72],\n",
       "       [ 72,  95,  91,  87,  89],\n",
       "       [ 67,  84,  75,  88,  79],\n",
       "       [ 59,  82,  71,  73,  72],\n",
       "       [ 75, 110,  87, 103,  90],\n",
       "       [ 68,  79,  83,  70,  84],\n",
       "       [ 57, 108,  61, 108,  63],\n",
       "       [ 68,  94,  70,  96,  70],\n",
       "       [ 77,  89,  77,  92,  82],\n",
       "       [ 79,  78,  80,  78,  86],\n",
       "       [ 52, 101,  54, 102,  56],\n",
       "       [ 59,  87,  70,  85,  69],\n",
       "       [ 58,  95,  64,  96,  70],\n",
       "       [ 56,  73,  73,  63,  73],\n",
       "       [ 57,  72,  67,  67,  76],\n",
       "       [ 58, 113,  72, 106,  70],\n",
       "       [ 78,  89,  90,  83,  90],\n",
       "       [ 54,  86,  67,  81,  68],\n",
       "       [ 66,  70,  72,  74,  79],\n",
       "       [ 77,  88,  94,  83,  94],\n",
       "       [ 64, 105,  60, 100,  65],\n",
       "       [ 53, 102,  67,  92,  70],\n",
       "       [ 50, 115,  57, 118,  64],\n",
       "       [ 64,  83,  72,  84,  79],\n",
       "       [ 56,  93,  65,  97,  69],\n",
       "       [ 77,  90,  97,  84,  87],\n",
       "       [ 61, 103,  74,  93,  80],\n",
       "       [ 71,  76,  80,  80,  89],\n",
       "       [ 52,  96,  72,  90,  64],\n",
       "       [ 57, 112,  58, 113,  61],\n",
       "       [ 73,  92,  82,  94,  86],\n",
       "       [ 73,  87,  92,  77,  85],\n",
       "       [ 60,  86,  78,  81,  70],\n",
       "       [ 66, 102,  85,  96,  79],\n",
       "       [ 80,  81,  83,  81,  90],\n",
       "       [ 65,  94,  77,  87,  76],\n",
       "       [ 51, 100,  52, 101,  59],\n",
       "       [ 56,  91,  69,  82,  72],\n",
       "       [ 52,  74,  53,  77,  55],\n",
       "       [ 75,  95,  80,  98,  82],\n",
       "       [ 67,  80,  71,  84,  75],\n",
       "       [ 57,  92,  68,  84,  72],\n",
       "       [ 75, 114,  86, 107,  91],\n",
       "       [ 62,  71,  74,  62,  73],\n",
       "       [ 77,  95,  94,  89,  96],\n",
       "       [ 66, 114,  69, 116,  75],\n",
       "       [ 79, 114,  97, 106,  94],\n",
       "       [ 74,  71,  84,  61,  85],\n",
       "       [ 57,  88,  69,  80,  67],\n",
       "       [ 50,  70,  58,  71,  59],\n",
       "       [ 50, 114,  58, 118,  62],\n",
       "       [ 73,  96,  90,  86,  93],\n",
       "       [ 71, 115,  73, 118,  82],\n",
       "       [ 66,  81,  69,  84,  72],\n",
       "       [ 69,  76,  72,  77,  77],\n",
       "       [ 54,  74,  70,  65,  66],\n",
       "       [ 61, 107,  63, 111,  67],\n",
       "       [ 69,  94,  75,  95,  81],\n",
       "       [ 62,  96,  65,  96,  68],\n",
       "       [ 71,  77,  78,  78,  79],\n",
       "       [ 62,  94,  70,  94,  72],\n",
       "       [ 63,  71,  74,  66,  81],\n",
       "       [ 74, 110,  84, 101,  93],\n",
       "       [ 69,  74,  76,  75,  76],\n",
       "       [ 52,  84,  60,  88,  67],\n",
       "       [ 58,  99,  74,  91,  74],\n",
       "       [ 77,  78,  92,  70,  92],\n",
       "       [ 64, 106,  64, 108,  65],\n",
       "       [ 69,  76,  76,  78,  77],\n",
       "       [ 70, 113,  85, 105,  83],\n",
       "       [ 69,  90,  80,  85,  79],\n",
       "       [ 64,  77,  66,  81,  72],\n",
       "       [ 66,  82,  75,  82,  75],\n",
       "       [ 77,  87,  82,  91,  89],\n",
       "       [ 79,  77,  80,  77,  82],\n",
       "       [ 59,  83,  70,  78,  78],\n",
       "       [ 72,  78,  73,  80,  78],\n",
       "       [ 78,  82,  81,  86,  84],\n",
       "       [ 66,  80,  74,  83,  80],\n",
       "       [ 68, 112,  73, 115,  81],\n",
       "       [ 70,  92,  71,  95,  80],\n",
       "       [ 50,  94,  64,  86,  70],\n",
       "       [ 64, 107,  75, 102,  78],\n",
       "       [ 54,  85,  62,  89,  64],\n",
       "       [ 68, 115,  68, 117,  70],\n",
       "       [ 52, 108,  61, 110,  65],\n",
       "       [ 80, 111,  99, 101,  97],\n",
       "       [ 75,  87,  81,  88,  90],\n",
       "       [ 78, 115,  86, 117,  92],\n",
       "       [ 59,  80,  68,  84,  77],\n",
       "       [ 76, 104,  81, 106,  84],\n",
       "       [ 74, 102,  94,  92,  85],\n",
       "       [ 65, 111,  70, 111,  73],\n",
       "       [ 55,  94,  55,  97,  60],\n",
       "       [ 73,  84,  92,  75,  85],\n",
       "       [ 62, 107,  79,  99,  76],\n",
       "       [ 80, 109,  88, 110,  96],\n",
       "       [ 51,  75,  71,  69,  62],\n",
       "       [ 56,  74,  63,  77,  66],\n",
       "       [ 50,  71,  63,  61,  67],\n",
       "       [ 72, 106,  77, 109,  86],\n",
       "       [ 55,  90,  60,  92,  62],\n",
       "       [ 69,  97,  80,  92,  79],\n",
       "       [ 52,  93,  58,  97,  66],\n",
       "       [ 79, 101,  80, 103,  80],\n",
       "       [ 65,  98,  84,  93,  81],\n",
       "       [ 54, 107,  69, 102,  68],\n",
       "       [ 69,  75,  74,  75,  76],\n",
       "       [ 77, 105,  88,  97,  88],\n",
       "       [ 72, 108,  72, 111,  74],\n",
       "       [ 53,  89,  69,  80,  70],\n",
       "       [ 59,  89,  74,  82,  76],\n",
       "       [ 63, 110,  68, 113,  71],\n",
       "       [ 80,  78,  95,  71,  94],\n",
       "       [ 57,  89,  68,  83,  76],\n",
       "       [ 78, 108,  96, 102,  97],\n",
       "       [ 64,  88,  84,  78,  80],\n",
       "       [ 71,  92,  88,  86,  84],\n",
       "       [ 52, 112,  68, 105,  67],\n",
       "       [ 77,  79,  85,  83,  89],\n",
       "       [ 53,  98,  60,  98,  67],\n",
       "       [ 60,  72,  64,  76,  69],\n",
       "       [ 76,  75,  76,  78,  81],\n",
       "       [ 61,  82,  72,  75,  75],\n",
       "       [ 64,  76,  70,  76,  76],\n",
       "       [ 75, 106,  81, 108,  86],\n",
       "       [ 70, 107,  90,  97,  81],\n",
       "       [ 59,  80,  59,  82,  64]], dtype=int64)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "36633d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  79.56204379562044\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score\n",
    "print(\"Accuracy is \", accuracy_score(Y_test,Y_pred_en)*100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8288ad54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [0.57446809, 0.42553191],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [1.        , 0.        ],\n",
       "       [0.57446809, 0.42553191],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.57446809, 0.42553191],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.57446809, 0.42553191],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.57446809, 0.42553191],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.57446809, 0.42553191],\n",
       "       [1.        , 0.        ],\n",
       "       [0.57446809, 0.42553191],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.57446809, 0.42553191],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.57446809, 0.42553191],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [1.        , 0.        ],\n",
       "       [0.57446809, 0.42553191],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.57446809, 0.42553191],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03773585, 0.96226415],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.64125561, 0.35874439],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probibilities\n",
    "Depression_Entropy.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3f4d4b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53, 22],\n",
       "       [ 6, 56]], dtype=int64)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wrongly classified instances\n",
    "confusion_matrix(Y_test,Y_pred_en, labels= [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "23e7707e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717948717948718"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision Score\n",
    "precision_score(Y_test,Y_pred_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8d6f75ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3544615 , 0.        , 0.60123814, 0.02980764, 0.01449272])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Depression_Entropy.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60649e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad75fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
